\chapter{Future Work}

\section{Lemmatization}
Apply lemmatization techniques during preprocessing to standardize text and improve embedding quality.

\section{Embedding Generation}
Generate embeddings using the \textit{original model} and the \textit{fine-tuned model} on test articles to avoid data leakage from training data.

% \section{Text Splitting}
% Apply techniques such as \textit{LangChain recursive splitting} to divide articles into smaller text chunks, facilitating effective embedding and retrieval.

\section{Embedding Comparison}
Compare embeddings from both models for each text chunk using similarity metrics such as \textit{cosine similarity} or other distance measures.

\section{Question Generation}
Use high-performing language models, such as \textit{LLaMA 3.1 70B}, to generate contextually relevant questions from the text chunks.

\section{Information Retrieval Evaluation}
Retrieve \textit{Top-K text chunks} based on embedding similarity scores for each question and evaluate performance using metrics like \textit{hit rate}.

\section{LLM Response Testing}
Validate the retrieved information by prompting the LLM with retrieved text and assessing its accuracy in answering the generated questions.
